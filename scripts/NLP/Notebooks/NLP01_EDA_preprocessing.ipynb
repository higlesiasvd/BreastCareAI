{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hugo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/hugo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_pdfs(directory):\n",
    "    \"\"\"\n",
    "    Extracts text from all PDF files in a directory and saves them in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    directory (str): Path to the directory containing PDF files\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with filenames and extracted text\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    filenames = []\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.pdf'):\n",
    "            full_path = os.path.join(directory, file)\n",
    "            \n",
    "            try:\n",
    "                # Open the PDF\n",
    "                reader = PdfReader(full_path)\n",
    "                full_text = \"\"\n",
    "                \n",
    "                # Extract text from each page\n",
    "                for page in reader.pages:\n",
    "                    full_text += page.extract_text() + \" \"\n",
    "                \n",
    "                # Save the text and filename\n",
    "                texts.append(full_text)\n",
    "                filenames.append(file)\n",
    "                print(f\"Successfully processed: {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file}: {e}\")\n",
    "    \n",
    "    # Create a DataFrame with extracted texts\n",
    "    df_texts = pd.DataFrame({\n",
    "        'filename': filenames,\n",
    "        'text': texts\n",
    "    })\n",
    "    \n",
    "    return df_texts\n",
    "\n",
    "# Replace \"path/to/your/pdfs\" with the actual path to your PDF files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses text: removes special characters,\n",
    "    converts to lowercase, tokenizes, removes stopwords, and applies stemming.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): The text to preprocess\n",
    "    \n",
    "    Returns:\n",
    "    str: Preprocessed text\n",
    "    \"\"\"\n",
    "    # Configure stemmer for Spanish\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    \n",
    "    # Convert to lowercase and remove special characters\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Remove special characters\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text, language='spanish')\n",
    "    \n",
    "    # Remove stopwords and apply stemming\n",
    "    processed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return ' '.join(processed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_corpus():\n",
    "    \"\"\"\n",
    "    Creates a corpus of questions and answers based on breast cancer medical information in Spanish.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing question-answer pairs with categories\n",
    "    \"\"\"\n",
    "    # This is a simplified version. In a real project,\n",
    "    # you would segment the documents into thematic sections\n",
    "    # and generate relevant question-answer pairs.\n",
    "    \n",
    "    corpus_qa = [\n",
    "        # Examples of question-answer pairs with their categories\n",
    "        {\"pregunta\": \"¿Qué es el cáncer de mama?\", \n",
    "         \"respuesta\": \"El cáncer de mama es una enfermedad en la que las células del tejido mamario crecen de forma descontrolada. Existen diferentes tipos de cáncer de mama dependiendo de qué células de la mama se convierten en cancerosas.\", \n",
    "         \"categoria\": \"definicion\"},\n",
    "        \n",
    "        {\"pregunta\": \"¿Cuáles son los síntomas del cáncer de mama?\", \n",
    "         \"respuesta\": \"Los síntomas del cáncer de mama pueden incluir un bulto en el seno, secreción sanguinolenta del pezón y cambios en la forma o textura del pezón o del seno.\", \n",
    "         \"categoria\": \"sintomas\"},\n",
    "        \n",
    "        {\"pregunta\": \"¿Cómo se diagnostica el cáncer de mama?\", \n",
    "         \"respuesta\": \"El cáncer de mama se puede diagnosticar mediante exámenes clínicos de las mamas, mamografías, ultrasonidos, resonancias magnéticas y biopsias de áreas sospechosas.\", \n",
    "         \"categoria\": \"diagnostico\"},\n",
    "        \n",
    "        {\"pregunta\": \"¿Cuáles son los factores de riesgo para el cáncer de mama?\", \n",
    "         \"respuesta\": \"Los factores de riesgo incluyen edad, mutaciones genéticas, antecedentes familiares, antecedentes personales de cáncer de mama, tejido mamario denso y ciertos factores de estilo de vida.\", \n",
    "         \"categoria\": \"factores_riesgo\"},\n",
    "        \n",
    "        {\"pregunta\": \"¿Qué tratamientos están disponibles para el cáncer de mama?\", \n",
    "         \"respuesta\": \"Los tratamientos pueden incluir cirugía, radioterapia, quimioterapia, terapia hormonal, terapia dirigida e inmunoterapia.\", \n",
    "         \"categoria\": \"tratamiento\"},\n",
    "        \n",
    "        {\"pregunta\": \"¿Cuáles son las etapas del cáncer de mama?\", \n",
    "         \"respuesta\": \"Las etapas del cáncer de mama van de 0 a IV, siendo la etapa 0 un cáncer no invasivo y la etapa IV un cáncer metastásico que se ha extendido a otras partes del cuerpo.\", \n",
    "         \"categoria\": \"etapas\"},\n",
    "        \n",
    "        # Add more examples based on sections in your documents\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame(corpus_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes_model(corpus_qa):\n",
    "    \"\"\"\n",
    "    Trains a Naive Bayes model to classify questions into categories.\n",
    "    \n",
    "    Parameters:\n",
    "    corpus_qa (pandas.DataFrame): DataFrame with question-answer pairs\n",
    "    \n",
    "    Returns:\n",
    "    sklearn.pipeline.Pipeline: Trained model pipeline\n",
    "    \"\"\"\n",
    "    # Prepare the data\n",
    "    X = corpus_qa['pregunta'].apply(preprocess_text)\n",
    "    y = corpus_qa['categoria']\n",
    "    \n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create a processing and classification pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer(max_features=5000)),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = pipeline.score(X_test, y_test)\n",
    "    print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "    \n",
    "    return pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotCancerMama:\n",
    "    def __init__(self, ruta_modelo, corpus_qa):\n",
    "        \"\"\"\n",
    "        Initializes the chatbot by loading the trained model and response corpus.\n",
    "        \n",
    "        Parameters:\n",
    "        ruta_modelo (str): Path to the saved model\n",
    "        corpus_qa (pandas.DataFrame): DataFrame with question-answer pairs\n",
    "        \"\"\"\n",
    "        self.modelo = load(ruta_modelo)\n",
    "        self.corpus_qa = corpus_qa\n",
    "        \n",
    "        # Create a dictionary of responses by category\n",
    "        self.respuestas_por_categoria = {}\n",
    "        for _, fila in corpus_qa.iterrows():\n",
    "            categoria = fila['categoria']\n",
    "            respuesta = fila['respuesta']\n",
    "            \n",
    "            if categoria not in self.respuestas_por_categoria:\n",
    "                self.respuestas_por_categoria[categoria] = []\n",
    "            \n",
    "            self.respuestas_por_categoria[categoria].append(respuesta)\n",
    "    \n",
    "    def obtener_respuesta(self, pregunta):\n",
    "        \"\"\"\n",
    "        Processes the user's question and returns an appropriate response.\n",
    "        \n",
    "        Parameters:\n",
    "        pregunta (str): User's question\n",
    "        \n",
    "        Returns:\n",
    "        str: Chatbot's response\n",
    "        \"\"\"\n",
    "        # Preprocess the question\n",
    "        pregunta_procesada = preprocess_text(pregunta)\n",
    "        \n",
    "        # Predict the category\n",
    "        categoria_predicha = self.modelo.predict([pregunta_procesada])[0]\n",
    "        \n",
    "        # Get a response from that category\n",
    "        # In a more advanced system, you could implement a more sophisticated selection\n",
    "        import random\n",
    "        respuestas_disponibles = self.respuestas_por_categoria.get(categoria_predicha, \n",
    "            [\"Lo siento, no tengo información sobre eso.\"])\n",
    "        \n",
    "        return random.choice(respuestas_disponibles)\n",
    "\n",
    "# Example usage\n",
    "# corpus_qa = pd.read_csv(\"corpus_qa_cancer_mama.csv\")\n",
    "# chatbot = ChatbotCancerMama('modelo_chatbot_cancer_mama.joblib', corpus_qa)\n",
    "\n",
    "def iniciar_chat(chatbot):\n",
    "    \"\"\"\n",
    "    Starts an interactive chat session with the chatbot.\n",
    "    \n",
    "    Parameters:\n",
    "    chatbot (ChatbotCancerMama): An initialized chatbot instance\n",
    "    \"\"\"\n",
    "    print(\"Chatbot de Asesoramiento sobre Cáncer de Mama\")\n",
    "    print(\"Escribe 'salir' para terminar la conversación.\")\n",
    "    \n",
    "    while True:\n",
    "        pregunta = input(\"\\nTú: \")\n",
    "        \n",
    "        if pregunta.lower() == 'salir':\n",
    "            print(\"¡Hasta pronto!\")\n",
    "            break\n",
    "        \n",
    "        respuesta = chatbot.obtener_respuesta(pregunta)\n",
    "        print(f\"Chatbot: {respuesta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_frases_relevantes(texto, n_frases=3):\n",
    "    \"\"\"\n",
    "    Divides the text into sentences and extracts the most relevant ones.\n",
    "    \n",
    "    Parameters:\n",
    "    texto (str): Text to extract phrases from\n",
    "    n_frases (int): Number of phrases to extract\n",
    "    \n",
    "    Returns:\n",
    "    list: List of extracted phrases\n",
    "    \"\"\"\n",
    "    # Split text into sentences (simplified)\n",
    "    frases = re.split(r'[.!?]+', texto)\n",
    "    frases = [frase.strip() for frase in frases if len(frase.strip()) > 10]\n",
    "    \n",
    "    return frases[:n_frases]  # In a real system, you'd use a ranking algorithm\n",
    "\n",
    "class ChatbotAvanzado(ChatbotCancerMama):\n",
    "    def __init__(self, ruta_modelo, corpus_qa, df_textos):\n",
    "        \"\"\"\n",
    "        Initializes an enhanced chatbot that can search through the original documents.\n",
    "        \n",
    "        Parameters:\n",
    "        ruta_modelo (str): Path to the saved model\n",
    "        corpus_qa (pandas.DataFrame): DataFrame with question-answer pairs\n",
    "        df_textos (pandas.DataFrame): DataFrame with the original document texts\n",
    "        \"\"\"\n",
    "        super().__init__(ruta_modelo, corpus_qa)\n",
    "        self.df_textos = df_textos\n",
    "        \n",
    "        # Vectorize all documents for search\n",
    "        self.vectorizador = TfidfVectorizer(max_features=5000)\n",
    "        textos_procesados = df_textos['texto_procesado'].tolist()\n",
    "        self.matriz_documentos = self.vectorizador.fit_transform(textos_procesados)\n",
    "        \n",
    "    def buscar_informacion_adicional(self, pregunta, top_k=2):\n",
    "        \"\"\"\n",
    "        Searches for additional information in the original documents.\n",
    "        \n",
    "        Parameters:\n",
    "        pregunta (str): User's question\n",
    "        top_k (int): Number of most relevant documents to consider\n",
    "        \n",
    "        Returns:\n",
    "        str: Additional information from relevant documents\n",
    "        \"\"\"\n",
    "        # Vectorize the question\n",
    "        vector_pregunta = self.vectorizador.transform([preprocess_text(pregunta)])\n",
    "        \n",
    "        # Calculate similarity with documents\n",
    "        similitudes = cosine_similarity(vector_pregunta, self.matriz_documentos)[0]\n",
    "        \n",
    "        # Find the most relevant documents\n",
    "        indices_relevantes = np.argsort(similitudes)[-top_k:]\n",
    "        \n",
    "        # Extract relevant phrases from those documents\n",
    "        informacion_adicional = []\n",
    "        for idx in indices_relevantes:\n",
    "            texto_completo = self.df_textos.iloc[idx]['texto']\n",
    "            frases = extraer_frases_relevantes(texto_completo)\n",
    "            informacion_adicional.extend(frases)\n",
    "        \n",
    "        return \"\\n\".join(informacion_adicional)\n",
    "    \n",
    "    def obtener_respuesta(self, pregunta):\n",
    "        \"\"\"\n",
    "        Enhanced version that combines classification with information search.\n",
    "        \n",
    "        Parameters:\n",
    "        pregunta (str): User's question\n",
    "        \n",
    "        Returns:\n",
    "        str: Chatbot's response with additional information\n",
    "        \"\"\"\n",
    "        respuesta_base = super().obtener_respuesta(pregunta)\n",
    "        info_adicional = self.buscar_informacion_adicional(pregunta)\n",
    "        \n",
    "        return f\"{respuesta_base}\\n\\nInformación adicional:\\n{info_adicional}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary data and initialize the chatbot\n",
    "def probar_chatbot():\n",
    "    \"\"\"\n",
    "    Function to test the chatbot with some sample questions.\n",
    "    \"\"\"\n",
    "    # In a real notebook, you would load your actual saved files\n",
    "    try:\n",
    "        df_textos = pd.read_csv(\"textos_cancer_mama.csv\")\n",
    "        corpus_qa = pd.read_csv(\"corpus_qa_cancer_mama.csv\")\n",
    "        \n",
    "        # Apply preprocessing to the texts if needed\n",
    "        if 'texto_procesado' not in df_textos.columns:\n",
    "            print(\"Preprocesando textos...\")\n",
    "            df_textos['texto_procesado'] = df_textos['texto'].apply(preprocess_text)\n",
    "            \n",
    "        # Initialize the advanced chatbot\n",
    "        chatbot = ChatbotAvanzado('modelo_chatbot_cancer_mama.joblib', corpus_qa, df_textos)\n",
    "        \n",
    "        # Test with some sample questions\n",
    "        preguntas_prueba = [\n",
    "            \"¿Qué es el cáncer de mama?\",\n",
    "            \"¿Qué síntomas debo vigilar?\",\n",
    "            \"¿Cómo se diagnostica el cáncer de mama?\",\n",
    "            \"¿Cuáles son las opciones de tratamiento?\",\n",
    "            \"¿Estoy en riesgo de tener cáncer de mama?\"\n",
    "        ]\n",
    "        \n",
    "        print(\"=== Resultados de Prueba del Chatbot ===\")\n",
    "        for pregunta in preguntas_prueba:\n",
    "            print(f\"\\nPregunta: {pregunta}\")\n",
    "            respuesta = chatbot.obtener_respuesta(pregunta)\n",
    "            print(f\"Respuesta: {respuesta}\")\n",
    "            \n",
    "        print(\"\\n=== Chat Interactivo ===\")\n",
    "        print(\"Ahora puedes hacer tus propias preguntas (escribe 'salir' para terminar):\")\n",
    "        \n",
    "        while True:\n",
    "            pregunta_usuario = input(\"\\nTú: \")\n",
    "            if pregunta_usuario.lower() == 'salir':\n",
    "                print(\"¡Hasta pronto!\")\n",
    "                break\n",
    "            \n",
    "            respuesta = chatbot.obtener_respuesta(pregunta_usuario)\n",
    "            print(f\"Chatbot: {respuesta}\")\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"\\nPara ejecutar esta prueba, primero necesitas:\")\n",
    "        print(\"1. Extraer texto de tus archivos PDF\")\n",
    "        print(\"2. Crear y guardar tu corpus de preguntas y respuestas\")\n",
    "        print(\"3. Entrenar y guardar tu modelo\")\n",
    "        \n",
    "# probar_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed: 12. Cáncer mamario en hombres autor Gloria Mesa, Gustavo Matute y Manuela Estrada.pdf\n",
      "Error processing 04. El proceso del cáncer de mama. Valoración, diagnóstico, y planificación de cuidados autor Lorena Gómez Mora.pdf: PyCryptodome is required for AES algorithm\n",
      "Successfully processed: 15. Protocolo de tratamiento del cáncer de mama autor Hospital Donostia.pdf\n",
      "Successfully processed: prevencion-factores-riesgo.pdf\n",
      "Successfully processed: 02. Guía para entender el cáncer de mama autor Rivas, Leticia.pdf\n",
      "Successfully processed: 06. Cáncer de Mama, Trabajo y Sociedad autor Encarna Aguilar Jiménez, Fernando Bandrés Moya y Luisa Mercedes Capdevila García.pdf\n",
      "Successfully processed: Guia-Oncosur-de-Cancer-de-Mama.pdf\n",
      "Successfully processed: ES-Cancer-de-Mama-Guia-para-Pacientes.pdf\n",
      "Successfully processed: protocolo_cancer_mama_2021.pdf\n",
      "Successfully processed: guia-descargable-que-es-la-radioterapia.pdf\n",
      "Successfully processed: Cuestiones frecuentes.pdf\n",
      "Successfully processed: 01. Guía para Pacientes. Cáncer de mama autor Ramírez-Morera, A., Tristan-López M., Landaverde-Recinos D.,Arce-Lara C..pdf\n",
      "Error processing 05. El cáncer de mama autor Rebeca Nieto Flaño.pdf: PyCryptodome is required for AES algorithm\n",
      "Successfully processed: que-es-la-quimioterapia.pdf\n",
      "Successfully processed: GuiaCancerDeMama_2018_INTERACTIVO.pdf\n"
     ]
    }
   ],
   "source": [
    "df = extract_text_from_pdfs('/Volumes/Proyecto Hugo/breast-cancer-analysis/papers/Base de conocimiento del programa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio_pdfs = \"ruta/a/tus/pdfs\"  \n",
    "df_guias_medicas = extract_text_from_pdfs(directorio_pdfs)\n",
    "\n",
    "# Save the extracted texts to a CSV file for future use\n",
    "df_guias_medicas.to_csv(\"textos_cancer_mama.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
